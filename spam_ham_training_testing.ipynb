{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle \n",
    "from tqdm import tqdm\n",
    "import nltk, re, pprint\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "wpt = WordPunctTokenizer()\n",
    "np.set_printoptions(threshold='nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(file_name):\n",
    "    myfile = open(file_name)\n",
    "    mytext = myfile.read()\n",
    "    mytxt = mytext.splitlines()\n",
    "    myfile.close()\n",
    "    return mytxt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get training data\n",
    "mytxt = get_data(\"SMSSpamCollection.train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get dev data\n",
    "mytxt_dev = get_data(\"SMSSpamCollection.devel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get test data\n",
    "mytxt_test = get_data(\"SMSSpamCollection.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the words in training\n",
    "vocab_list = []\n",
    "for line in mytxt:\n",
    "    token_line = wpt.tokenize(line) \n",
    "    del token_line[0]\n",
    "    for token in token_line:\n",
    "        vocab_list.append(token)\n",
    "\n",
    "pickle.dump(vocab_list, open (\"vocab_list.p\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the vocab list (features)\n",
    "ult_vocab = set(vocab_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getting the original theta vector\n",
    "\n",
    "theta = []\n",
    "for i in range(0, len(ult_vocab)):\n",
    "\ttheta.append(0)\n",
    "theta.append(0) #add bias\n",
    "theta_array = np.asarray(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getting message vectors\n",
    "def message_vectors(data):\n",
    "    list_of_message_vectors = []\n",
    "    for line in tqdm(data):\n",
    "        message_vector = []\n",
    "        token_line = wpt.tokenize(line) \n",
    "        if token_line[0] == \"spam\":\n",
    "            message_vector.append(1)\n",
    "        else:\n",
    "            message_vector.append(0)\n",
    "        \n",
    "        hamless = token_line[1:]\n",
    "        for item in ult_vocab:\n",
    "            if item in hamless:\n",
    "                message_vector.append(hamless.count(item))\n",
    "            else:\n",
    "                message_vector.append(0)\n",
    "        message_vector.append(1) #adding \"fake feature\" to counter bias\n",
    "        message_vector_array = np.asarray(message_vector)\n",
    "        list_of_message_vectors.append(message_vector_array)\n",
    "    return list_of_message_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3345/3345 [00:13<00:00, 242.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3345"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the training data message vectors\n",
    "list_of_message_vectors = message_vectors(mytxt)\n",
    "list_of_message_vectors[5]\n",
    "len(list_of_message_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1115/1115 [00:04<00:00, 240.22it/s]\n"
     ]
    }
   ],
   "source": [
    "#getting the devel data message vectors\n",
    "list_of_message_vectors_dev = message_vectors(mytxt_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1114/1114 [00:04<00:00, 251.49it/s]\n"
     ]
    }
   ],
   "source": [
    "#getting the test data message vectors\n",
    "list_of_message_vectors_test = message_vectors(mytxt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(message_vectors, theta_array, learning_rate, mini_batch, epoch):\n",
    "    list_of_thetas = []\n",
    "    for epoch in tqdm(range(epoch)):\n",
    "        correct_list = []\n",
    "        wrong_list = []\n",
    "        np.random.shuffle(message_vectors)\n",
    "        for i in range(0, len(message_vectors) - mini_batch, mini_batch):\n",
    "            adjust = 0\n",
    "            for j in range(0, mini_batch):\n",
    "                y = float(message_vectors[i + j][0])\n",
    "                message_vector = message_vectors[i + j][1:]\n",
    "                z = np.dot(theta_array, message_vector)\n",
    "                sigmoid = 1 / (1 + math.exp(-z))\n",
    "                adjust = adjust + learning_rate*(y - sigmoid)*message_vector\t\n",
    "                if sigmoid >= 0.5:\n",
    "                    decision = 1\n",
    "                else:\n",
    "                    decision =  0\n",
    "                if decision == y:\n",
    "                    correct_list.append (1)\n",
    "                else:\n",
    "                    wrong_list.append(0) \n",
    "            adjust = adjust/mini_batch\n",
    "            theta_array = theta_array + adjust\n",
    "            list_of_thetas.append(theta_array)\n",
    "    return list_of_thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:03<00:00,  5.39it/s]\n"
     ]
    }
   ],
   "source": [
    "#saving model\n",
    "list_of_thetas = train(list_of_message_vectors, theta_array, 0.5, 5, 20)\n",
    "\n",
    "model = list_of_thetas[-1]\n",
    "pickle.dump(model, open (\"theta_array.p\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testing(message_vectors, theta_array, learning_rate):\n",
    "    accuracy = []\n",
    "    correct_list = []\n",
    "    wrong_list = []\n",
    "    for message in message_vectors:\n",
    "        message_vector = message[1:]\n",
    "        z = np.dot(theta_array, message_vector)\n",
    "        sigmoid = 1 / (1 + math.exp(-z))\n",
    "        y = message[0]\n",
    "        if sigmoid >= 0.5:\n",
    "            decision = 1\n",
    "        else:\n",
    "            decision =  0\n",
    "        if decision == y:\n",
    "            correct_list.append (1)\n",
    "        else:\n",
    "            wrong_list.append(0)\n",
    "\n",
    "    accuracy = float(len(correct_list))/ float(len(message_vectors))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9856373429084381"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = testing(list_of_message_vectors_test, model, 0.5)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
